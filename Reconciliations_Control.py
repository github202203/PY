# Databricks notebook source
# DBTITLE 1,Common Libs
# MAGIC %run ../Common/Master

# COMMAND ----------

dbutils.widgets.text("subject","Velocity","subject")
dbutils.widgets.text("layer","Raw","layer")
dbutils.widgets.text("auditID","22073","auditID")
dbutils.widgets.text("type","RowCount","type")
# declaring sql db connection properties
str_subject         = dbutils.widgets.get("subject")
str_layer           = dbutils.widgets.get("layer")
str_auditID         = dbutils.widgets.get("auditID")
int_auditID         = int(dbutils.widgets.get("auditID"))
str_type            = dbutils.widgets.get("type")
str_currentDateTime = datetime.strptime(str(datetime.now()), "%Y-%m-%d %H:%M:%S.%f")
str_sqlTableName    = "Reconciliation.AuditResults"

# COMMAND ----------

# DBTITLE 1,Getting Metadata for Row Counts
if(str_type == "RowCount"):
  try:
    df_results = fn_GetRecRowMetaData(str_auditID, str_layer, str_subject)
    # Print info
    print("Info: Successfully retrieved MetaData for Audit ID : " + str_auditID )
  except:
    raise(Exception("Error: Failed to get meta data  details")) 
    
if(df_results.count() == 0):
    print("Warning: No metadata details were found for AuditQueueID: " + str_auditID  ) 

# COMMAND ----------

# DBTITLE 1,Time Stamped Row Counts
###############################
#For each entity in Audit Queue
##############################
for row in df_results.collect():
  try:
    # (row.SourcePattern == 'TimeStamped') and 
    if ((row.DestinationPattern == 'TimeStamped')):
      df = fn_RunTimeStampedRec(df_results,str_type)
      print("Info: Successfully added Reconciliation Results for '" + row.DestinationEntity + "' ("  + str(int_auditID) + ") into '" + str_sqlTableName + "' table")
    else:
      df = fn_RunNonTimeStampedRec(df_results,str_type)
  except:
    raise(Exception("Info: Failed reconciliations for '" + row.DestinationEntity + "' ("  + str(int_auditID) + ")'"))

# COMMAND ----------

# DBTITLE 1,Get Meta Data for Sum Values
df_ColumnResults = fn_GetRecHashMetaData(str_auditID, str_layer, str_subject)
# Print info
print("Info: Successfully retrieved MetaData for Audit ID : " + str_auditID )

# COMMAND ----------

#HashTotal Reconciliation Output
if str_type == 'HashTotal':
  schema = StructType([
    StructField('Type', StringType(), False),
    StructField('SourceValue', IntegerType(), True),
    StructField('EntityName', StringType(), True),    
    StructField('Name', StringType(), True),
    StructField('DestinationValue', IntegerType(), True),
    StructField('Subject', StringType(), True),
    StructField('Layer', StringType(), True), 
    StructField('Pattern', StringType(), True),
    StructField('AuditID', IntegerType(), True)
  ])
  df = sqlContext.createDataFrame(sc.emptyRDD(), schema)
  #For each entity in Audit Queue
  for row in df_ColumnResults.collect():
     #Source
    if(row.SourcePattern == 'TimeStamped') &  (row.IsAutoGenerated != 0) and (row.IsAutoGenerated != 0):
      df_src = fn_TimeStampedSource(row.IsSourceAutoGenerated,row.SourceLayer,row.SourceSubject,row.SourceEntity,row.StartTimeStamp, row.EndTimeStamp, int_auditID,str_type,row.DestinationEntity, row.SourceColumn,row.SourceFormat)
    elif (row.SourcePattern == 'Version') &  (row.IsAutoGenerated != 0) and (row.IsAutoGenerated != 0):
      df_src = fn_versionSource(row.IsSourceAutoGenerated, row.SourceLayer,row.SourceSubject,row.SourceEntity,row.Version, int_auditID,str_type,row.DestinationEntity, row.SourceColumn,row.SourceFormat) 
    elif (row.SourcePattern == 'VersionTimeStamped')&  (row.IsAutoGenerated != 0) and (row.IsAutoGenerated != 0):
      df_src = fn_timeStampedVersionSource(row.IsSourceAutoGenerated,row.SourceLayer,row.SourceSubject,row.SourceEntity,row.TimeStamp, row.TimeStamp,row.Version, int_auditID,str_type,row.DestinationEntity, row.SourceColumn,row.SourceFormat) 
    elif (row.SourcePattern == 'Latest')&  (row.IsAutoGenerated != 0) and (row.IsAutoGenerated != 0):
      df_src = fn_latestSource(row.IsSourceAutoGenerated,row.SourceLayer,row.SourceSubject,row.SourceEntity, int_auditID,str_type,row.DestinationEntity, row.SourceColumn,row.SourceFormat)      
    #Destination
    if(row.DestinationPattern == 'TimeStamped'):
      int_dest = fn_TimeStampedDestination(row.IsAutoGenerated,row.DestinationLayer,row.DestinationSubject,row.StartTimeStamp, row.EndTimeStamp,int_auditID,str_type,row.DestinationEntity, row.DestinationColumn,row.DestinationFormat)
    elif (row.DestinationPattern == 'Version')&  (row.IsAutoGenerated != 0) and (row.IsAutoGenerated != 0):
      int_dest = fn_versionDestination(row.IsAutoGenerated,row.DestinationLayer,row.DestinationSubject, row.Version, int_auditID,str_type,row.DestinationEntity, row.DestinationColumn,row.DestinationFormat)
    elif (row.DestinationPattern == 'VersionTimeStamped')&  (row.IsAutoGenerated != 0) and (row.IsAutoGenerated != 0):
      int_dest = fn_timeStampedVersionDestination(row.IsAutoGenerated,row.DestinationLayer,row.DestinationSubject,row.TimeStamp, row.TimeStamp, row.Version,int_auditID,str_type,row.DestinationEntity, row.DestinationColumn,row.DestinationFormat)
    elif (row.DestinationPattern == 'Latest')& ((row.IsAutoGenerated != 0) and (row.IsAutoGenerated != 0)):
      int_dest = fn_latestDestination(row.IsAutoGenerated,row.DestinationLayer,row.DestinationSubject,int_auditID,str_type,row.DestinationEntity, row.DestinationColumn,row.DestinationFormat)
      
     #Full Custom so takes source & destination from the same file. 
    if(row.SourcePattern == 'TimeStamped') & (row.IsSourceAutoGenerated == 0) and (row.IsAutoGenerated == 0):
      df = fn_TimeStampedCustom(row.DestinationLayer,row.DestinationSubject,row.StartTimeStamp, row.EndTimeStamp,int_auditID,str_type,row.DestinationEntity, row.DestinationColumn,row.DestinationFormat)
    elif (row.SourcePattern == 'Version') & (row.IsSourceAutoGenerated == 0) and (row.IsAutoGenerated == 0):
      df = fn_versionCustom(row.DestinationLayer,row.DestinationSubject, row.Version, int_auditID,str_type,row.DestinationEntity, row.DestinationColumn,row.DestinationFormat)
    elif (row.SourcePattern == 'VersionTimeStamped')& (row.IsSourceAutoGenerated == 0) and (row.IsAutoGenerated == 0):
      df = fn_timeStampedVersionCustom(row.DestinationLayer,row.DestinationSubject,row.TimeStamp, row.TimeStamp, row.Version,int_auditID,str_type,row.DestinationEntity, row.DestinationColumn,row.DestinationFormat)
    elif (row.SourcePattern == 'Latest')& (row.IsSourceAutoGenerated == 0) and (row.IsAutoGenerated == 0):
      df = fn_latestCustom(row.DestinationLayer,row.DestinationSubject,int_auditID,str_type,row.DestinationEntity, row.DestinationColumn,row.DestinationFormat)
   #Union All columns for output per entity
    df_outputHC = df_src.withColumn('DestinationValue',lit(int_dest))
    df_outputHC = df_output.withColumn('Subject',lit(row.DestinationSubject))\
                 .withColumn('Layer',lit(row.DestinationLayer))\
                 .withColumn('Pattern',lit(row.DestinationPattern))\
                 .withColumn('AuditID',lit(int_auditID))\
                 .select('Type','SourceValue','EntityName','Name','DestinationValue','Subject','Layer','Pattern','AuditID')
    
    df = df.withColumn('Subject',lit(row.DestinationSubject))\
                 .withColumn('Layer',lit(row.DestinationLayer))\
                 .withColumn('Pattern',lit(row.DestinationPattern))\
                 .withColumn('AuditID',lit(int_auditID))\
                 .select('Type','SourceValue','EntityName','Name','DestinationValue','Subject','Layer','Pattern','AuditID')
    df_outputHC = df_outputHC.union(df)
    df_outputHC.createOrReplaceTempView("vw_reconciliationResults")
    df_appendData = spark.sql("""
    SELECT Pattern                 as Pattern
     ,SourceValue             as SourceCount
     ,DestinationValue        as TargetCount
     ,EntityName              as EntityName
     ,Subject                 as Subject
     ,Layer                   as Layer
     ,Name                    as ColumnName
     ,Type                    as ReconciliationType
     ,cast('{0}'as timestamp) as ReconciliationDate
     ,AuditID                 as AuditQueueID
     ,''                      as Tolerance
      FROM vw_reconciliationResults
    """.format(str_currentDateTime))
    print("Info: Created dataframe: 'df_appendData' to append to '" + str_sqlTableName + "' table")
    fn_appendSqlTable(df_appendData, str_sqlTableName)
    print("Info: Successfully added Reconciliation Results for '" + row.DestinationEntity + "' ("  + str(int_auditID) + ") into '" + str_sqlTableName + "' table")
else:
  print('Not a HashTotal Reconciliation')

# COMMAND ----------

 # df = spark.read.format("parquet").option("header", "true").load("dbfs:/mnt/main/Reconciliation/Audit/Internal/Results_RowCount.parquet")
 # display(df)
